{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12e461af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:30:25.659586Z",
     "start_time": "2022-01-11T16:30:23.583588Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import random\n",
    "import pprint\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from keras_frcnn import config, data_generators\n",
    "from keras_frcnn import losses as losses\n",
    "import keras_frcnn.roi_helpers as roi_helpers\n",
    "from tensorflow.python.keras.utils import generic_utils\n",
    "\n",
    "sys.setrecursionlimit(40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b5e19df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:30:25.675585Z",
     "start_time": "2022-01-11T16:30:25.662588Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras_frcnn.simple_parser import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6de1bcf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:30:25.691589Z",
     "start_time": "2022-01-11T16:30:25.677601Z"
    }
   },
   "outputs": [],
   "source": [
    "# pass the settings from the command line, and persist them in the config object\n",
    "C = config.Config()\n",
    "\n",
    "C.use_horizontal_flips = False\n",
    "C.use_vertical_flips = False\n",
    "C.rot_90 = False\n",
    "\n",
    "C.model_path = './model_frcnn.hdf5'\n",
    "model_path_regex = re.match(\"^(.+)(\\.hdf5)$\", C.model_path)\n",
    "\n",
    "C.num_rois = 32\n",
    "\n",
    "from keras_frcnn import resnet as nn\n",
    "C.network = 'resnet50'\n",
    "\n",
    "C.base_net_weights = nn.get_weight_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6042ae2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:30:26.356681Z",
     "start_time": "2022-01-11T16:30:25.693586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing annotation files\n"
     ]
    }
   ],
   "source": [
    "train_imgs, classes_count, class_mapping = get_data('train_annotate.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c6e22cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:30:26.372676Z",
     "start_time": "2022-01-11T16:30:26.358587Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WBC': 0, 'RBC': 1, 'Platelets': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba0bfe81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:30:26.547677Z",
     "start_time": "2022-01-11T16:30:26.373589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing annotation files\n"
     ]
    }
   ],
   "source": [
    "val_imgs, _, _ = get_data('val_annotate.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64b020ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:30:26.563750Z",
     "start_time": "2022-01-11T16:30:26.549585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images per class:\n",
      "{'Platelets': 216, 'RBC': 2564, 'WBC': 236, 'bg': 0}\n",
      "Num classes (including bg) = 4\n"
     ]
    }
   ],
   "source": [
    "if 'bg' not in classes_count:\n",
    "    classes_count['bg'] = 0\n",
    "    class_mapping['bg'] = len(class_mapping)\n",
    "\n",
    "C.class_mapping = class_mapping\n",
    "\n",
    "inv_map = {v: k for k, v in class_mapping.items()}\n",
    "\n",
    "print('Training images per class:')\n",
    "pprint.pprint(classes_count)\n",
    "print(f'Num classes (including bg) = {len(classes_count)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83072170",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:30:26.579458Z",
     "start_time": "2022-01-11T16:30:26.564772Z"
    }
   },
   "outputs": [],
   "source": [
    "config_output_filename = 'config.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46ac3d40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:30:26.594708Z",
     "start_time": "2022-01-11T16:30:26.580490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config has been written to config.pickle, and can be loaded when testing to ensure correct results\n"
     ]
    }
   ],
   "source": [
    "with open(config_output_filename, 'wb') as config_f:\n",
    "    pickle.dump(C, config_f)\n",
    "    print(f'Config has been written to {config_output_filename}, '\n",
    "          f'and can be loaded when testing to ensure correct results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65452fb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:30:26.610379Z",
     "start_time": "2022-01-11T16:30:26.597725Z"
    }
   },
   "outputs": [],
   "source": [
    "random.shuffle(train_imgs)\n",
    "\n",
    "num_imgs = len(train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6339597b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:30:26.626312Z",
     "start_time": "2022-01-11T16:30:26.611353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num train samples 232\n",
      "Num val samples 59\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'Num train samples {len(train_imgs)}')\n",
    "print(f'Num val samples {len(val_imgs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8791aed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:30:26.641347Z",
     "start_time": "2022-01-11T16:30:26.627312Z"
    }
   },
   "outputs": [],
   "source": [
    "data_gen_train = data_generators.get_anchor_gt(train_imgs, classes_count, C,\n",
    "                                               nn.get_img_output_length,\n",
    "                                               K.image_data_format(), mode='train')\n",
    "data_gen_val = data_generators.get_anchor_gt(val_imgs, classes_count, C, nn.get_img_output_length,\n",
    "                                             K.image_data_format(), mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca27e34b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:30:26.656962Z",
     "start_time": "2022-01-11T16:30:26.642334Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape_img = (3, None, None)\n",
    "else:\n",
    "    input_shape_img = (None, None, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c55952b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:30:26.672189Z",
     "start_time": "2022-01-11T16:30:26.658896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e16ff57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:30:26.703299Z",
     "start_time": "2022-01-11T16:30:26.673007Z"
    }
   },
   "outputs": [],
   "source": [
    "img_input = Input(shape=input_shape_img)\n",
    "roi_input = Input(shape=(None, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9de753b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:30:28.586798Z",
     "start_time": "2022-01-11T16:30:26.704318Z"
    }
   },
   "outputs": [],
   "source": [
    "shared_layers = nn.nn_base(img_input, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6eb164df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:30:28.602779Z",
     "start_time": "2022-01-11T16:30:28.588717Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, None, None, 1024) dtype=float32 (created by layer 'activation_39')>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebe84454",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:30:28.633843Z",
     "start_time": "2022-01-11T16:30:28.604735Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# define the RPN, built on the base layers\n",
    "num_anchors = len(C.anchor_box_scales) * len(C.anchor_box_ratios)\n",
    "rpn = nn.rpn(shared_layers, num_anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3478876",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:30:28.649111Z",
     "start_time": "2022-01-11T16:30:28.634847Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, None, None, 9) dtype=float32 (created by layer 'rpn_out_class')>,\n",
       " <KerasTensor: shape=(None, None, None, 36) dtype=float32 (created by layer 'rpn_out_regress')>,\n",
       " <KerasTensor: shape=(None, None, None, 1024) dtype=float32 (created by layer 'activation_39')>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80229d64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:30:29.825649Z",
     "start_time": "2022-01-11T16:30:28.650624Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier = nn.classifier(shared_layers, roi_input, C.num_rois,\n",
    "                           nb_classes=len(classes_count), trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc70f515",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:30:29.856647Z",
     "start_time": "2022-01-11T16:30:29.827649Z"
    }
   },
   "outputs": [],
   "source": [
    "model_rpn = Model(img_input, rpn[:2])\n",
    "model_classifier = Model([img_input, roi_input], classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e4786d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:30:29.872615Z",
     "start_time": "2022-01-11T16:30:29.858615Z"
    }
   },
   "outputs": [],
   "source": [
    "# this is a model that holds both the RPN and the classifier,\n",
    "# used to load/save weights for the models\n",
    "model_all = Model([img_input, roi_input], rpn[:2] + classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a523121",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:30:29.903650Z",
     "start_time": "2022-01-11T16:30:29.874632Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\kaggle\\keras-frcnn\\frcnn\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(lr=1e-5)\n",
    "optimizer_classifier = Adam(lr=1e-5)\n",
    "model_rpn.compile(optimizer=optimizer,\n",
    "                  loss=[losses.rpn_loss_cls(num_anchors), losses.rpn_loss_regr(num_anchors)])\n",
    "model_classifier.compile(optimizer=optimizer_classifier, loss=[losses.class_loss_cls,\n",
    "                                                               losses.class_loss_regr(\n",
    "                                                                   len(classes_count) - 1)],\n",
    "                         metrics={f'dense_class_{len(classes_count)}': 'accuracy'})\n",
    "model_all.compile(optimizer='sgd', loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f1c142c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:30:29.918646Z",
     "start_time": "2022-01-11T16:30:29.904616Z"
    }
   },
   "outputs": [],
   "source": [
    "epoch_length = 1000\n",
    "num_epochs = int(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de037a23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:30:29.934642Z",
     "start_time": "2022-01-11T16:30:29.920870Z"
    }
   },
   "outputs": [],
   "source": [
    "iter_num = 0\n",
    "\n",
    "losses = np.zeros((epoch_length, 5))\n",
    "rpn_accuracy_rpn_monitor = []\n",
    "rpn_accuracy_for_epoch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0c4947d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:57:57.784912Z",
     "start_time": "2022-01-11T16:30:29.935614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Epoch 1/2\n",
      "1000/1000 [==============================] - 837s 820ms/step - rpn_cls: 3.2855 - rpn_regr: 0.2553 - detector_cls: 0.7756 - detector_regr: 5.4989\n",
      "Mean number of bounding boxes from RPN overlapping ground truth boxes: 24.486\n",
      "Classifier accuracy for bounding boxes from RPN: 0.576875\n",
      "Loss RPN classifier: 3.285486337224722\n",
      "Loss RPN regression: 0.2552903192457743\n",
      "Loss Detector classifier: 0.7756384629756212\n",
      "Loss Detector regression: 5.498929038527189\n",
      "Elapsed time: 836.9372932910919\n",
      "Total loss decreased from inf to 9.815344157973307, saving weights\n",
      "Epoch 2/2\n",
      "Average number of overlapping bounding boxes from RPN = 24.486 for 1000 previous iterations\n",
      "1000/1000 [==============================] - 809s 809ms/step - rpn_cls: 3.0706 - rpn_regr: 0.2295 - detector_cls: 0.6594 - detector_regr: -3.6891\n",
      "Mean number of bounding boxes from RPN overlapping ground truth boxes: 24.226\n",
      "Classifier accuracy for bounding boxes from RPN: 0.65884375\n",
      "Loss RPN classifier: 3.070572531109231\n",
      "Loss RPN regression: 0.2294521200035233\n",
      "Loss Detector classifier: 0.6594145148396492\n",
      "Loss Detector regression: -3.689131682147039\n",
      "Elapsed time: 810.2452130317688\n",
      "Total loss decreased from 9.815344157973307 to 0.2703074838053645, saving weights\n",
      "Training complete, exiting.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "best_loss = np.Inf\n",
    "\n",
    "class_mapping_inv = {v: k for k, v in class_mapping.items()}\n",
    "print('Starting training')\n",
    "\n",
    "vis = True\n",
    "\n",
    "for epoch_num in range(num_epochs):\n",
    "\n",
    "    progbar = generic_utils.Progbar(epoch_length)\n",
    "    print(f'Epoch {epoch_num + 1}/{num_epochs}')\n",
    "\n",
    "    while True:\n",
    "        if len(rpn_accuracy_rpn_monitor) == epoch_length and C.verbose:\n",
    "            mean_overlapping_bboxes = float(sum(rpn_accuracy_rpn_monitor)) / len(\n",
    "                rpn_accuracy_rpn_monitor)\n",
    "            rpn_accuracy_rpn_monitor = []\n",
    "            print(\n",
    "                f'Average number of overlapping bounding boxes '\n",
    "                f'from RPN = {mean_overlapping_bboxes} for {epoch_length} previous iterations')\n",
    "            if mean_overlapping_bboxes == 0:\n",
    "                print('RPN is not producing bounding boxes that overlap the ground truth boxes.'\n",
    "                      ' Check RPN settings or keep training.')\n",
    "\n",
    "        X, Y, img_data = next(data_gen_train)\n",
    "\n",
    "        loss_rpn = model_rpn.train_on_batch(X, Y)\n",
    "\n",
    "        P_rpn = model_rpn.predict_on_batch(X)\n",
    "\n",
    "        R = roi_helpers.rpn_to_roi(P_rpn[0], P_rpn[1], C, K.image_data_format(),\n",
    "                                   use_regr=True, overlap_thresh=0.7, max_boxes=300)\n",
    "        # note: calc_iou converts from (x1,y1,x2,y2) to (x,y,w,h) format\n",
    "        X2, Y1, Y2, IouS = roi_helpers.calc_iou(R, img_data, C, class_mapping)\n",
    "\n",
    "        if X2 is None:\n",
    "            rpn_accuracy_rpn_monitor.append(0)\n",
    "            rpn_accuracy_for_epoch.append(0)\n",
    "            continue\n",
    "\n",
    "        neg_samples = np.where(Y1[0, :, -1] == 1)\n",
    "        pos_samples = np.where(Y1[0, :, -1] == 0)\n",
    "\n",
    "        if len(neg_samples) > 0:\n",
    "            neg_samples = neg_samples[0]\n",
    "        else:\n",
    "            neg_samples = []\n",
    "\n",
    "        if len(pos_samples) > 0:\n",
    "            pos_samples = pos_samples[0]\n",
    "        else:\n",
    "            pos_samples = []\n",
    "\n",
    "        rpn_accuracy_rpn_monitor.append(len(pos_samples))\n",
    "        rpn_accuracy_for_epoch.append((len(pos_samples)))\n",
    "\n",
    "        if C.num_rois > 1:\n",
    "            if len(pos_samples) < C.num_rois // 2:\n",
    "                selected_pos_samples = pos_samples.tolist()\n",
    "            else:\n",
    "                selected_pos_samples = np.random.choice(pos_samples, C.num_rois // 2,\n",
    "                                                        replace=False).tolist()\n",
    "            try:\n",
    "                selected_neg_samples = np.random.choice(neg_samples,\n",
    "                                                        C.num_rois - len(selected_pos_samples),\n",
    "                                                        replace=False).tolist()\n",
    "            except:\n",
    "                selected_neg_samples = np.random.choice(neg_samples,\n",
    "                                                        C.num_rois - len(selected_pos_samples),\n",
    "                                                        replace=True).tolist()\n",
    "\n",
    "            sel_samples = selected_pos_samples + selected_neg_samples\n",
    "        else:\n",
    "            # in the extreme case where num_rois = 1, we pick a random pos or neg sample\n",
    "            selected_pos_samples = pos_samples.tolist()\n",
    "            selected_neg_samples = neg_samples.tolist()\n",
    "            if np.random.randint(0, 2):\n",
    "                sel_samples = random.choice(neg_samples)\n",
    "            else:\n",
    "                sel_samples = random.choice(pos_samples)\n",
    "\n",
    "        loss_class = model_classifier.train_on_batch([X, X2[:, sel_samples, :]],\n",
    "                                                     [Y1[:, sel_samples, :],\n",
    "                                                      Y2[:, sel_samples, :]])\n",
    "\n",
    "        losses[iter_num, 0] = loss_rpn[1]\n",
    "        losses[iter_num, 1] = loss_rpn[2]\n",
    "\n",
    "        losses[iter_num, 2] = loss_class[1]\n",
    "        losses[iter_num, 3] = loss_class[2]\n",
    "        losses[iter_num, 4] = loss_class[3]\n",
    "\n",
    "        progbar.update(iter_num + 1,\n",
    "                       [('rpn_cls', losses[iter_num, 0]),\n",
    "                        ('rpn_regr', losses[iter_num, 1]),\n",
    "                        ('detector_cls', losses[iter_num, 2]),\n",
    "                        ('detector_regr', losses[iter_num, 3])])\n",
    "\n",
    "        iter_num += 1\n",
    "\n",
    "        if iter_num == epoch_length:\n",
    "            loss_rpn_cls = np.mean(losses[:, 0])\n",
    "            loss_rpn_regr = np.mean(losses[:, 1])\n",
    "            loss_class_cls = np.mean(losses[:, 2])\n",
    "            loss_class_regr = np.mean(losses[:, 3])\n",
    "            class_acc = np.mean(losses[:, 4])\n",
    "\n",
    "            mean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch)) / len(\n",
    "                rpn_accuracy_for_epoch)\n",
    "            rpn_accuracy_for_epoch = []\n",
    "\n",
    "            if C.verbose:\n",
    "                print(\n",
    "                    f'Mean number of bounding boxes from RPN overlapping '\n",
    "                    f'ground truth boxes: {mean_overlapping_bboxes}')\n",
    "                print(f'Classifier accuracy for bounding boxes from RPN: {class_acc}')\n",
    "                print(f'Loss RPN classifier: {loss_rpn_cls}')\n",
    "                print(f'Loss RPN regression: {loss_rpn_regr}')\n",
    "                print(f'Loss Detector classifier: {loss_class_cls}')\n",
    "                print(f'Loss Detector regression: {loss_class_regr}')\n",
    "                print(f'Elapsed time: {time.time() - start_time}')\n",
    "\n",
    "            curr_loss = loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr\n",
    "            iter_num = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "            if curr_loss < best_loss:\n",
    "                if C.verbose:\n",
    "                    print(\n",
    "                        f'Total loss decreased from {best_loss} to {curr_loss}, saving weights')\n",
    "                best_loss = curr_loss\n",
    "            model_all.save_weights(model_path_regex.group(1) + \"_\" + '{:04d}'.format(\n",
    "                epoch_num) + model_path_regex.group(2))\n",
    "\n",
    "            break\n",
    "\n",
    "print('Training complete, exiting.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a249106e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:57:57.814002Z",
     "start_time": "2022-01-11T16:57:57.789021Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 416, 554, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c21098",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
